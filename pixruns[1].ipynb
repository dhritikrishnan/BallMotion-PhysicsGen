{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating environment at: /jet/home/rnagaraj/my_hw4_env ...\n",
      "Installing libraries...\n",
      "Collecting torch\n",
      "  Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Pillow\n",
      "  Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting ipykernel\n",
      "  Downloading ipykernel-7.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.2/113.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting packaging>=20.0 (from matplotlib)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting click>=8.0.1 (from wandb)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting platformdirs (from wandb)\n",
      "  Using cached platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3 (from wandb)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml (from wandb)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting requests<3,>=2.0.0 (from wandb)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.46.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting comm>=0.1.1 (from ipykernel)\n",
      "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting debugpy>=1.6.5 (from ipykernel)\n",
      "  Downloading debugpy-1.8.17-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting ipython>=7.23.1 (from ipykernel)\n",
      "  Downloading ipython-9.7.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting jupyter-client>=8.0.0 (from ipykernel)\n",
      "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel)\n",
      "  Downloading jupyter_core-5.9.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting matplotlib-inline>=0.1 (from ipykernel)\n",
      "  Downloading matplotlib_inline-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting nest-asyncio>=1.4 (from ipykernel)\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting psutil>=5.7 (from ipykernel)\n",
      "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "Collecting pyzmq>=25 (from ipykernel)\n",
      "  Downloading pyzmq-27.1.0-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting tornado>=6.2 (from ipykernel)\n",
      "  Downloading tornado-6.5.2-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting traitlets>=5.4.0 (from ipykernel)\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting decorator>=4.3.2 (from ipython>=7.23.1->ipykernel)\n",
      "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting ipython-pygments-lexers>=1.0.0 (from ipython>=7.23.1->ipykernel)\n",
      "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting jedi>=0.18.1 (from ipython>=7.23.1->ipykernel)\n",
      "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel)\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel)\n",
      "  Downloading prompt_toolkit-3.0.52-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pygments>=2.11.0 (from ipython>=7.23.1->ipykernel)\n",
      "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting stack_data>=0.6.0 (from ipython>=7.23.1->ipykernel)\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3->wandb)\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3->wandb)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.0.0->wandb)\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.0.0->wandb)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.0.0->wandb)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.0.0->wandb)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.18.1->ipython>=7.23.1->ipykernel)\n",
      "  Downloading parso-0.8.5-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel)\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel)\n",
      "  Downloading wcwidth-0.2.14-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Collecting executing>=1.2.0 (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel)\n",
      "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting asttokens>=2.1.0 (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel)\n",
      "  Downloading asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pure-eval (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel)\n",
      "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "Using cached torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading ipykernel-7.1.0-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.0/118.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
      "Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading debugpy-1.8.17-py2.py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fonttools-4.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.0/201.0 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading ipython-9.7.0-py3-none-any.whl (618 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.9/618.9 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_core-5.9.1-py3-none-any.whl (29 kB)\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib_inline-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading networkx-3.6-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached platformdirs-4.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.3/263.3 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.6/463.6 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyzmq-27.1.0-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.0/857.0 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading sentry_sdk-2.46.0-py2.py3-none-any.whl (406 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m406.3/406.3 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading tornado-6.5.2-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.4/391.4 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
      "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
      "Downloading parso-0.8.5-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "Downloading wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\n",
      "Installing collected packages: pure-eval, ptyprocess, nvidia-cusparselt-cu12, mpmath, wcwidth, urllib3, typing-extensions, triton, traitlets, tqdm, tornado, sympy, smmap, six, pyzmq, pyyaml, pyparsing, pygments, psutil, protobuf, platformdirs, Pillow, pexpect, parso, packaging, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, nest-asyncio, MarkupSafe, kiwisolver, idna, fsspec, fonttools, filelock, executing, decorator, debugpy, cycler, comm, click, charset_normalizer, certifi, asttokens, annotated-types, typing-inspection, stack_data, sentry-sdk, requests, python-dateutil, pydantic-core, prompt_toolkit, opencv-python, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, matplotlib-inline, jupyter-core, jinja2, jedi, ipython-pygments-lexers, gitdb, contourpy, pydantic, nvidia-cusolver-cu12, matplotlib, jupyter-client, ipython, gitpython, wandb, torch, ipykernel, torchvision\n",
      "Successfully installed MarkupSafe-3.0.3 Pillow-12.0.0 annotated-types-0.7.0 asttokens-3.0.1 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 comm-0.2.3 contourpy-1.3.3 cycler-0.12.1 debugpy-1.8.17 decorator-5.2.1 executing-2.2.1 filelock-3.20.0 fonttools-4.61.0 fsspec-2025.10.0 gitdb-4.0.12 gitpython-3.1.45 idna-3.11 ipykernel-7.1.0 ipython-9.7.0 ipython-pygments-lexers-1.1.1 jedi-0.19.2 jinja2-3.1.6 jupyter-client-8.6.3 jupyter-core-5.9.1 kiwisolver-1.4.9 matplotlib-3.10.7 matplotlib-inline-0.2.1 mpmath-1.3.0 nest-asyncio-1.6.0 networkx-3.6 numpy-2.2.6 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 opencv-python-4.12.0.88 packaging-25.0 parso-0.8.5 pexpect-4.9.0 platformdirs-4.5.0 prompt_toolkit-3.0.52 protobuf-6.33.1 psutil-7.1.3 ptyprocess-0.7.0 pure-eval-0.2.3 pydantic-2.12.5 pydantic-core-2.41.5 pygments-2.19.2 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pyyaml-6.0.3 pyzmq-27.1.0 requests-2.32.5 sentry-sdk-2.46.0 six-1.17.0 smmap-5.0.2 stack_data-0.6.3 sympy-1.14.0 torch-2.9.1 torchvision-0.24.1 tornado-6.5.2 tqdm-4.67.1 traitlets-5.14.3 triton-3.5.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0 wandb-0.23.0 wcwidth-0.2.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Registering kernel...\n",
      "Installed kernelspec my_hw4_kernel in /jet/home/rnagaraj/.local/share/jupyter/kernels/my_hw4_kernel\n",
      "\n",
      "SUCCESS! Now refresh the page and change your kernel.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Create a fresh environment in your HOME directory (safest place)\n",
    "#    We use 'expanduser' to find your home folder automatically (~/)\n",
    "env_path = os.path.expanduser(\"~/my_hw4_env\")\n",
    "print(f\"Creating environment at: {env_path} ...\")\n",
    "\n",
    "!python -m venv {env_path}\n",
    "\n",
    "# 2. FORCE install libraries into this NEW environment\n",
    "#    We use the full path to the new pip executable\n",
    "print(\"Installing libraries...\")\n",
    "!{env_path}/bin/pip install torch torchvision numpy Pillow opencv-python matplotlib tqdm wandb ipykernel\n",
    "\n",
    "# 3. Register this environment as a Jupyter Kernel\n",
    "print(\"Registering kernel...\")\n",
    "!{env_path}/bin/python -m ipykernel install --user --name=my_hw4_kernel --display-name \"My HW4 Kernel\"\n",
    "\n",
    "print(\"\\nSUCCESS! Now refresh the page and change your kernel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (2.5.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: Pillow in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (11.0.0)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: matplotlib in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: tqdm in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: wandb in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (0.19.9)\n",
      "Requirement already satisfied: filelock in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (2.10.5)\n",
      "Requirement already satisfied: pyyaml in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (2.19.2)\n",
      "Requirement already satisfied: setproctitle in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (78.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.4.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, triton, sympy, opencv-python, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "\u001b[?25l\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: '/ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages/nvidia/cusparselt'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/20\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision numpy Pillow opencv-python matplotlib tqdm wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pix2Pix Implementation for PhysicsGen Motion Prediction\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    print(\"Installing wandb...\")\n",
    "    !pip install wandb -q\n",
    "    import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:20:54.963027Z",
     "iopub.status.busy": "2025-11-24T00:20:54.962672Z",
     "iopub.status.idle": "2025-11-24T00:21:01.837858Z",
     "shell.execute_reply": "2025-11-24T00:21:01.837105Z",
     "shell.execute_reply.started": "2025-11-24T00:20:54.963003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrishin\u001b[0m (\u001b[33mrishin-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['WANDB_API_KEY'] = 'c0568591bf53551942de5b598dcf8626dae19df1'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HW2P2_final_submission.zip  kaggle_data.json\n",
      "HW3P2_final_submission.zip  model_arch.txt\n",
      "HW3P2_v10.ipynb\t\t    model_metadata_2025-10-12_18-23.json\n",
      "IDL-hw4\t\t\t    model_metadata_2025-10-12_18-49.json\n",
      "README.txt\t\t    model_metadata_2025-10-31_15-12.json\n",
      "acknowledgement.txt\t    model_metadata_2025-11-09_19-09.json\n",
      "bounce_ball.zip\t\t    model_metadata_2025-11-09_19-21.json\n",
      "bounce_ball_data\t    my_hw4_env\n",
      "checkpoint\t\t    ondemand\n",
      "checkpoint_p3_new\t    submission.csv\n",
      "checkpoint_submission.json  verification_early_submission.csv\n",
      "checkpoints\t\t    wandb\n",
      "config.yaml\t\t    wandb_top_runs.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:22:43.610985Z",
     "iopub.status.busy": "2025-11-24T00:22:43.610245Z",
     "iopub.status.idle": "2025-11-24T00:22:43.619345Z",
     "shell.execute_reply": "2025-11-24T00:22:43.618535Z",
     "shell.execute_reply.started": "2025-11-24T00:22:43.610956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CombinedImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, split_direction='horizontal'):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.split_direction = split_direction\n",
    "        self.image_files = sorted([\n",
    "            f for f in os.listdir(self.data_dir) \n",
    "            if f.endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ])\n",
    "        \n",
    "        print(f\"{len(self.image_files)} combined images from {data_dir}\")\n",
    "        \n",
    "        if self.image_files:\n",
    "            first_img = Image.open(self.data_dir / self.image_files[0])\n",
    "            w, h = first_img.size\n",
    "            print(f\"  Image size: {w}x{h}\")\n",
    "            \n",
    "            if split_direction == 'horizontal':\n",
    "                if w > h * 1.5:\n",
    "                    print(f\"  Will split into: {w//2}x{h} (left) and {w//2}x{h} (right)\")\n",
    "                else:\n",
    "                    print(f\"  Image might not be horizontally combined\")\n",
    "            else:\n",
    "                if h > w * 1.5:\n",
    "                    print(f\"  Will split into: {w}x{h//2} (top) and {w}x{h//2} (bottom)\")\n",
    "                else:\n",
    "                    print(f\"  Image might not be vertically combined\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data_dir / self.image_files[idx]\n",
    "        combined_img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        w, h = combined_img.size\n",
    "        \n",
    "        if self.split_direction == 'horizontal':\n",
    "            mid = w // 2\n",
    "            input_img = combined_img.crop((0, 0, mid, h))\n",
    "            target_img = combined_img.crop((mid, 0, w, h))\n",
    "        else:\n",
    "            mid = h // 2\n",
    "            input_img = combined_img.crop((0, 0, w, mid))\n",
    "            target_img = combined_img.crop((0, mid, w, h))\n",
    "        \n",
    "        if self.transform:\n",
    "            input_img = self.transform(input_img)\n",
    "            target_img = self.transform(target_img)\n",
    "        \n",
    "        return input_img, target_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:22:50.797601Z",
     "iopub.status.busy": "2025-11-24T00:22:50.797324Z",
     "iopub.status.idle": "2025-11-24T00:22:50.804674Z",
     "shell.execute_reply": "2025-11-24T00:22:50.803959Z",
     "shell.execute_reply.started": "2025-11-24T00:22:50.797581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_data_loaders(data_root, batch_size=18, image_size=256, num_workers=2, \n",
    "                       split_direction='horizontal'):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    print(f\"Split direction: {split_direction}\")\n",
    "    \n",
    "    \n",
    "    train_path = Path(data_root) / 'train_double'\n",
    "    print(\"\\nTrain set:\")\n",
    "    train_dataset = CombinedImageDataset(\n",
    "        str(train_path), \n",
    "        transform=transform,\n",
    "        split_direction=split_direction\n",
    "    )\n",
    "    \n",
    "    val_path = Path(data_root) / 'val_double'\n",
    "    test_path = Path(data_root) / 'test_double'\n",
    "    \n",
    "    if val_path.exists():\n",
    "        print(\"\\nValidation set:\")\n",
    "        val_dataset = CombinedImageDataset(\n",
    "            str(val_path), \n",
    "            transform=transform,\n",
    "            split_direction=split_direction\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\nValidation set: Creating 10% split from training\")\n",
    "        train_size = int(0.9 * len(train_dataset))\n",
    "        val_size = len(train_dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            train_dataset, [train_size, val_size]\n",
    "        )\n",
    "    \n",
    "    if test_path.exists():\n",
    "        print(\"\\nTest set:\")\n",
    "        test_dataset = CombinedImageDataset(\n",
    "            str(test_path), \n",
    "            transform=transform,\n",
    "            split_direction=split_direction\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\nTest set: Using val set\")\n",
    "        test_dataset = val_dataset\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                             shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, \n",
    "                           shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                            shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:22:58.315995Z",
     "iopub.status.busy": "2025-11-24T00:22:58.315727Z",
     "iopub.status.idle": "2025-11-24T00:22:58.322669Z",
     "shell.execute_reply": "2025-11-24T00:22:58.321837Z",
     "shell.execute_reply.started": "2025-11-24T00:22:58.315976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True, dropout=0.0):\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels, affine=True))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
    "        super(UNetUp, self).__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:23:01.602238Z",
     "iopub.status.busy": "2025-11-24T00:23:01.601486Z",
     "iopub.status.idle": "2025-11-24T00:23:01.610161Z",
     "shell.execute_reply": "2025-11-24T00:23:01.609368Z",
     "shell.execute_reply.started": "2025-11-24T00:23:01.602207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False) \n",
    "        self.down2 = UNetDown(64, 128)                          \n",
    "        self.down3 = UNetDown(128, 256)                       \n",
    "        self.down4 = UNetDown(256, 512)          \n",
    "        self.down5 = UNetDown(512, 512)\n",
    "        self.down6 = UNetDown(512, 512)\n",
    "        self.down7 = UNetDown(512, 512)\n",
    "        self.down8 = UNetDown(512, 512, normalize=False) \n",
    "\n",
    "        \n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up3 = UNetUp(1024, 512, dropout=0.5) \n",
    "        self.up4 = UNetUp(1024, 512)\n",
    "        self.up5 = UNetUp(1024, 256)\n",
    "        self.up6 = UNetUp(512, 128) \n",
    "        self.up7 = UNetUp(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, out_channels, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "\n",
    "        \n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "\n",
    "        return self.final(u7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:01.305132Z",
     "iopub.status.busy": "2025-11-24T00:25:01.304413Z",
     "iopub.status.idle": "2025-11-24T00:25:01.311058Z",
     "shell.execute_reply": "2025-11-24T00:25:01.310343Z",
     "shell.execute_reply.started": "2025-11-24T00:25:01.305105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=6):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters, affine=True))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(discriminator, real_A, real_B, fake_B, device, lambda_gp=10):\n",
    "    \n",
    "    batch_size = real_B.size(0)\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    \n",
    "    interpolates = (alpha * real_B + (1 - alpha) * fake_B).requires_grad_(True)\n",
    "    d_interpolates = discriminator(real_A, interpolates)\n",
    "    fake = torch.ones(d_interpolates.size(), device=device, requires_grad=False)\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lambda_gp\n",
    "    \n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(generator, discriminator, train_loader, optimizer_G, optimizer_D, \n",
    "                criterion_GAN, criterion_L1, lambda_L1, lambda_gp, device, epoch):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    epoch_g_loss = 0\n",
    "    epoch_d_loss = 0\n",
    "    epoch_gan_loss = 0\n",
    "    epoch_l1_loss = 0\n",
    "    epoch_gp_loss = 0 \n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1} - Training')\n",
    "    for batch_idx, (real_A, real_B) in enumerate(pbar):\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "        \n",
    "        batch_size = real_A.size(0)\n",
    "        valid = torch.ones((batch_size, 1, 16, 16), device=device, requires_grad=False)\n",
    "        fake = torch.zeros((batch_size, 1, 16, 16), device=device, requires_grad=False)\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        fake_B = generator(real_A)\n",
    "        pred_fake = discriminator(real_A, fake_B)\n",
    "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "        loss_L1 = criterion_L1(fake_B, real_B)\n",
    "        loss_G = loss_GAN + lambda_L1 * loss_L1\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        pred_real = discriminator(real_A, real_B)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "        \n",
    "        pred_fake = discriminator(real_A, fake_B.detach())\n",
    "        loss_fake = criterion_GAN(pred_fake, fake)\n",
    "        \n",
    "        gp = compute_gradient_penalty(discriminator, real_A, real_B, \n",
    "                                     fake_B.detach(), device, lambda_gp)\n",
    "        \n",
    "        loss_D = 0.5 * (loss_real + loss_fake) + gp\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        epoch_g_loss += loss_G.item()\n",
    "        epoch_d_loss += loss_D.item()\n",
    "        epoch_gan_loss += loss_GAN.item()\n",
    "        epoch_l1_loss += loss_L1.item()\n",
    "        epoch_gp_loss += gp.item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            wandb.log({\n",
    "                'batch/g_loss': loss_G.item(),\n",
    "                'batch/d_loss': loss_D.item(),\n",
    "                'batch/gan_loss': loss_GAN.item(),\n",
    "                'batch/l1_loss': loss_L1.item(),\n",
    "                'batch/gp_loss': gp.item(),\n",
    "                'batch/step': epoch * len(train_loader) + batch_idx\n",
    "            })\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'G': f'{loss_G.item():.4f}',\n",
    "            'D': f'{loss_D.item():.4f}',\n",
    "            'L1': f'{loss_L1.item():.4f}',\n",
    "            'GP': f'{gp.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    return (epoch_g_loss/num_batches, epoch_d_loss/num_batches,\n",
    "            epoch_gan_loss/num_batches, epoch_l1_loss/num_batches,\n",
    "            epoch_gp_loss/num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "def calculate_roundness_loss(prediction):\n",
    "    \"\"\"\n",
    "    Calculates L_roundness: Penalty for geometric distortion.\n",
    "    \n",
    "    Note: Since the exact implementation depends on the specific paper's\n",
    "    definition (e.g., Hough transform differentiability or radial symmetry), \n",
    "    this uses a variance-based approach suitable for 'ball' shapes.\n",
    "    \n",
    "    It calculates the center of mass and penalizes variance in the \n",
    "    distance of activated pixels from that center.\n",
    "    \"\"\"\n",
    "    # 1. Create a coordinate grid\n",
    "    batch_size, _, h, w = prediction.size()\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(h), torch.arange(w), indexing='ij')\n",
    "    y_grid, x_grid = y_grid.to(prediction.device).float(), x_grid.to(prediction.device).float()\n",
    "    \n",
    "    # 2. Normalize prediction to treat as probability mass\n",
    "    pred_sum = torch.sum(prediction, dim=[2, 3], keepdim=True) + 1e-8\n",
    "    pred_norm = prediction / pred_sum\n",
    "    \n",
    "    # 3. Calculate Center of Mass (CoM)\n",
    "    com_x = torch.sum(pred_norm * x_grid, dim=[2, 3], keepdim=True)\n",
    "    com_y = torch.sum(pred_norm * y_grid, dim=[2, 3], keepdim=True)\n",
    "    \n",
    "    # 4. Calculate radial distance of every pixel from CoM\n",
    "    dist_sq = (x_grid - com_x)**2 + (y_grid - com_y)**2\n",
    "    \n",
    "    # 5. Calculate \"Roundness\" as the variance of these distances weighted by pixel intensity\n",
    "    # (Perfect circles have lower variance in radial distribution than irregular blobs)\n",
    "    weighted_dist_variance = torch.sum(pred_norm * dist_sq, dim=[2, 3])\n",
    "    \n",
    "    return torch.mean(weighted_dist_variance)\n",
    "\n",
    "def train_epoch_tpl(generator, discriminator, train_loader, optimizer_G, optimizer_D, \n",
    "                    criterion_GAN, lambda1, lambda2, lambda3, lambda_gp, device, epoch):\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    # Initialize metric trackers\n",
    "    metrics = {\n",
    "        'g_loss': 0, 'd_loss': 0, 'gan_loss': 0, \n",
    "        'mse_loss': 0, 'round_loss': 0, 'gp_loss': 0\n",
    "    }\n",
    "    \n",
    "    # Define MSE Loss for pixels (Lambda 1)\n",
    "    criterion_MSE = nn.MSELoss() \n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1} - TPL Training')\n",
    "    \n",
    "    for batch_idx, (real_A, real_B) in enumerate(pbar):\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "        \n",
    "        batch_size = real_A.size(0)\n",
    "        \n",
    "        # --- Discriminator Training ---\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Generate Fake images\n",
    "        fake_B = generator(real_A)\n",
    "        \n",
    "        # Real Loss\n",
    "        valid = torch.ones((batch_size, 1, 16, 16), device=device, requires_grad=False)\n",
    "        fake = torch.zeros((batch_size, 1, 16, 16), device=device, requires_grad=False)\n",
    "        \n",
    "        pred_real = discriminator(real_A, real_B)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "        \n",
    "        # Fake Loss (detach fake_B so we don't update G here)\n",
    "        pred_fake = discriminator(real_A, fake_B.detach())\n",
    "        loss_fake = criterion_GAN(pred_fake, fake)\n",
    "        \n",
    "        # Gradient Penalty (Optional: kept if using WGAN-GP, remove if using pure BCE)\n",
    "        gp = compute_gradient_penalty(discriminator, real_A, real_B, \n",
    "                                      fake_B.detach(), device, lambda_gp)\n",
    "        \n",
    "        loss_D = 0.5 * (loss_real + loss_fake) + gp\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # --- Generator Training (The TPL Update) ---\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # 1. BCE_valid (Lambda 3): Generator tries to fool D\n",
    "        pred_fake_G = discriminator(real_A, fake_B) # Re-compute for graph connection\n",
    "        loss_BCE_valid = criterion_GAN(pred_fake_G, valid)\n",
    "        \n",
    "        # 2. MSE_pixels (Lambda 1): Pixel-wise accuracy\n",
    "        loss_MSE = criterion_MSE(fake_B, real_B)\n",
    "        \n",
    "        # 3. L_roundness (Lambda 2): Geometric penalty\n",
    "        loss_Roundness = calculate_roundness_loss(fake_B)\n",
    "        \n",
    "        # Total Composite Loss Formula (Eq 1)\n",
    "        loss_G = (lambda1 * loss_MSE) + \\\n",
    "                 (lambda2 * loss_Roundness) + \\\n",
    "                 (lambda3 * loss_BCE_valid)\n",
    "                 \n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # --- Logging ---\n",
    "        metrics['g_loss'] += loss_G.item()\n",
    "        metrics['d_loss'] += loss_D.item()\n",
    "        metrics['gan_loss'] += loss_BCE_valid.item()\n",
    "        metrics['mse_loss'] += loss_MSE.item()\n",
    "        metrics['round_loss'] += loss_Roundness.item()\n",
    "        metrics['gp_loss'] += gp.item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            wandb.log({\n",
    "                'batch/g_loss': loss_G.item(),\n",
    "                'batch/d_loss': loss_D.item(),\n",
    "                'batch/gan_bce_loss': loss_BCE_valid.item(),\n",
    "                'batch/mse_loss': loss_MSE.item(),\n",
    "                'batch/round_loss': loss_Roundness.item(),\n",
    "                'batch/step': epoch * len(train_loader) + batch_idx\n",
    "            })\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'G': f'{loss_G.item():.4f}',\n",
    "            'MSE': f'{loss_MSE.item():.4f}',\n",
    "            'Round': f'{loss_Roundness.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    # Average metrics for the epoch\n",
    "    num_batches = len(train_loader)\n",
    "    return {k: v / num_batches for k, v in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:18.291728Z",
     "iopub.status.busy": "2025-11-24T00:25:18.291034Z",
     "iopub.status.idle": "2025-11-24T00:25:18.297939Z",
     "shell.execute_reply": "2025-11-24T00:25:18.297250Z",
     "shell.execute_reply.started": "2025-11-24T00:25:18.291703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate(generator, discriminator, val_loader, criterion_GAN, \n",
    "             criterion_L1, lambda_L1, device, epoch):\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    val_g_loss = 0\n",
    "    val_d_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for real_A, real_B in tqdm(val_loader, desc=f'Epoch {epoch+1} - Validation'):\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "            \n",
    "            batch_size = real_A.size(0)\n",
    "            valid = torch.ones((batch_size, 1, 16, 16), device=device)\n",
    "            fake = torch.zeros((batch_size, 1, 16, 16), device=device)\n",
    "            \n",
    "            fake_B = generator(real_A)\n",
    "            pred_fake = discriminator(real_A, fake_B)\n",
    "            loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "            loss_L1 = criterion_L1(fake_B, real_B)\n",
    "            loss_G = loss_GAN + lambda_L1 * loss_L1\n",
    "            \n",
    "            pred_real = discriminator(real_A, real_B)\n",
    "            loss_real = criterion_GAN(pred_real, valid)\n",
    "            pred_fake = discriminator(real_A, fake_B)\n",
    "            loss_fake = criterion_GAN(pred_fake, fake)\n",
    "            loss_D = 0.5 * (loss_real + loss_fake)\n",
    "            \n",
    "            val_g_loss += loss_G.item()\n",
    "            val_d_loss += loss_D.item()\n",
    "    \n",
    "    num_batches = len(val_loader)\n",
    "    return val_g_loss/num_batches, val_d_loss/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_pix2pix(generator, discriminator, train_loader, val_loader, \n",
    "                  config, device, save_dir='checkpoints'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    optimizer_G = optim.Adam(generator.parameters(), \n",
    "                            lr=config['lr_generator'], \n",
    "                            betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), \n",
    "                            lr=config['lr_discriminator'], \n",
    "                            betas=(0.5, 0.999))\n",
    "    \n",
    "    criterion_GAN = nn.MSELoss()\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    print(\"Starting Pix2Pix Training with Gradient Penalty\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Lambda L1: {config['lambda_l1']}\")\n",
    "    print(f\"Lambda GP: {config['lambda_gp']}\")  # Show GP weight\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Train with gradient penalty\n",
    "        train_g, train_d, train_gan, train_l1, train_gp = train_epoch(\n",
    "            generator, discriminator, train_loader,\n",
    "            optimizer_G, optimizer_D,\n",
    "            criterion_GAN, criterion_L1, \n",
    "            config['lambda_l1'], config['lambda_gp'],  # Pass lambda_gp\n",
    "            device, epoch\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_g, val_d = validate(\n",
    "            generator, discriminator, val_loader,\n",
    "            criterion_GAN, criterion_L1, config['lambda_l1'],\n",
    "            device, epoch\n",
    "        )\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        # Log to wandb (including GP)\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'train/g_loss': train_g,\n",
    "            'train/d_loss': train_d,\n",
    "            'train/gan_loss': train_gan,\n",
    "            'train/l1_loss': train_l1,\n",
    "            'train/gp_loss': train_gp,  # Log gradient penalty\n",
    "            'val/g_loss': val_g,\n",
    "            'val/d_loss': val_d,\n",
    "            'epoch_time': epoch_time\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nEpoch [{epoch+1}/{config['num_epochs']}] | Time: {epoch_time:.1f}s\")\n",
    "        print(f\"  Train - G: {train_g:.4f}, D: {train_d:.4f}, GP: {train_gp:.4f}\")\n",
    "        print(f\"  Val   - G: {val_g:.4f}, D: {val_d:.4f}\")\n",
    "        \n",
    "        if val_g < best_val_loss:\n",
    "            best_val_loss = val_g\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'val_loss': val_g,\n",
    "            }\n",
    "            torch.save(checkpoint, os.path.join(save_dir, 'best_pix2pix.pth'))\n",
    "            wandb.save(os.path.join(save_dir, 'best_pix2pix.pth'))\n",
    "            print(f\"  ✓ Saved best model\")\n",
    "        \n",
    "        # Visualize every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            visualize_results(generator, val_loader, device, epoch)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    wandb.run.summary['best_val_loss'] = best_val_loss\n",
    "    wandb.run.summary['total_training_time'] = total_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Training completed in {total_time/3600:.2f} hours\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:36.568622Z",
     "iopub.status.busy": "2025-11-24T00:25:36.568132Z",
     "iopub.status.idle": "2025-11-24T00:25:36.575482Z",
     "shell.execute_reply": "2025-11-24T00:25:36.574703Z",
     "shell.execute_reply.started": "2025-11-24T00:25:36.568601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_results(generator, val_loader, device, epoch):\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        real_A, real_B = next(iter(val_loader))\n",
    "        real_A = real_A.to(device)\n",
    "        fake_B = generator(real_A)\n",
    "        \n",
    "        def denorm(x):\n",
    "            return (x + 1) / 2\n",
    "        \n",
    "        num_vis = min(4, len(real_A))\n",
    "        fig, axes = plt.subplots(3, num_vis, figsize=(4*num_vis, 12))\n",
    "        \n",
    "        for i in range(num_vis):\n",
    "            input_img = denorm(real_A[i]).cpu().permute(1, 2, 0).numpy()\n",
    "            axes[0, i].imshow(input_img)\n",
    "            axes[0, i].set_title(f'Input {i+1}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            gen_img = denorm(fake_B[i]).cpu().permute(1, 2, 0).numpy()\n",
    "            axes[1, i].imshow(gen_img)\n",
    "            axes[1, i].set_title(f'Generated {i+1}')\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            target_img = denorm(real_B[i]).cpu().permute(1, 2, 0).numpy()\n",
    "            axes[2, i].imshow(target_img)\n",
    "            axes[2, i].set_title(f'Ground Truth {i+1}')\n",
    "            axes[2, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        wandb.log({f\"generations/epoch_{epoch+1}\": wandb.Image(fig), \"epoch\": epoch + 1})\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:46.778697Z",
     "iopub.status.busy": "2025-11-24T00:25:46.778004Z",
     "iopub.status.idle": "2025-11-24T00:25:46.783944Z",
     "shell.execute_reply": "2025-11-24T00:25:46.783217Z",
     "shell.execute_reply.started": "2025-11-24T00:25:46.778671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BallDetector:\n",
    "    \n",
    "    def __init__(self, ball_radius=15, min_radius=10, max_radius=25):\n",
    "        self.ball_radius = ball_radius\n",
    "        self.min_radius = min_radius\n",
    "        self.max_radius = max_radius\n",
    "    \n",
    "    def detect_ball(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        \n",
    "        blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "        circles = cv2.HoughCircles(\n",
    "            blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50,\n",
    "            param1=50, param2=30,\n",
    "            minRadius=self.min_radius, maxRadius=self.max_radius\n",
    "        )\n",
    "        \n",
    "        if circles is None or len(circles[0]) == 0:\n",
    "            return None\n",
    "        \n",
    "        circle = circles[0][0]\n",
    "        return {'position': (circle[0], circle[1]), 'radius': circle[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:50.735201Z",
     "iopub.status.busy": "2025-11-24T00:25:50.734599Z",
     "iopub.status.idle": "2025-11-24T00:25:50.970211Z",
     "shell.execute_reply": "2025-11-24T00:25:50.969412Z",
     "shell.execute_reply.started": "2025-11-24T00:25:50.735177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_pix2pix(generator, test_loader, device):\n",
    "    generator.eval()\n",
    "    detector = BallDetector()\n",
    "    \n",
    "    all_errors_x = []\n",
    "    all_errors_y = []\n",
    "    failed_predictions = 0\n",
    "    total_predictions = 0\n",
    "    sample_predictions = []\n",
    "    \n",
    "    print(\"Evaluating Pix2Pix Model\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (real_A, real_B) in enumerate(tqdm(test_loader, desc='Evaluating')):\n",
    "            real_A = real_A.to(device)\n",
    "            fake_B = generator(real_A)\n",
    "            \n",
    "            fake_imgs = ((fake_B + 1) / 2 * 255).cpu().numpy().astype(np.uint8)\n",
    "            real_imgs = ((real_B + 1) / 2 * 255).numpy().astype(np.uint8)\n",
    "            \n",
    "            for i in range(len(fake_imgs)):\n",
    "                total_predictions += 1\n",
    "                \n",
    "                pred = fake_imgs[i].transpose(1, 2, 0)\n",
    "                target = real_imgs[i].transpose(1, 2, 0)\n",
    "                \n",
    "                # Log first 10 samples\n",
    "                if len(sample_predictions) < 10:\n",
    "                    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "                    axes[0].imshow(pred)\n",
    "                    axes[0].set_title('Prediction')\n",
    "                    axes[0].axis('off')\n",
    "                    axes[1].imshow(target)\n",
    "                    axes[1].set_title('Ground Truth')\n",
    "                    axes[1].axis('off')\n",
    "                    plt.tight_layout()\n",
    "                    sample_predictions.append(wandb.Image(fig))\n",
    "                    plt.close()\n",
    "                \n",
    "                pred_ball = detector.detect_ball(pred)\n",
    "                target_ball = detector.detect_ball(target)\n",
    "                \n",
    "                if pred_ball is None or target_ball is None:\n",
    "                    failed_predictions += 1\n",
    "                    continue\n",
    "                \n",
    "                pos_error_x = abs(pred_ball['position'][0] - target_ball['position'][0])\n",
    "                pos_error_y = abs(pred_ball['position'][1] - target_ball['position'][1])\n",
    "                \n",
    "                all_errors_x.append(pos_error_x)\n",
    "                all_errors_y.append(pos_error_y)\n",
    "    \n",
    "    failure_rate = (failed_predictions / total_predictions) * 100\n",
    "    \n",
    "    results = {\n",
    "        'test/position_x_mean': np.mean(all_errors_x) if len(all_errors_x) > 0 else 0,\n",
    "        'test/position_x_std': np.std(all_errors_x) if len(all_errors_x) > 0 else 0,\n",
    "        'test/position_y_mean': np.mean(all_errors_y) if len(all_errors_y) > 0 else 0,\n",
    "        'test/position_y_std': np.std(all_errors_y) if len(all_errors_y) > 0 else 0,\n",
    "        'test/failure_rate': failure_rate,\n",
    "        'test/total_predictions': total_predictions,\n",
    "        'test/failed_predictions': failed_predictions\n",
    "    }\n",
    "    \n",
    "    wandb.log(results)\n",
    "    wandb.log({\"test/sample_predictions\": sample_predictions})\n",
    "    \n",
    "    comparison_table = wandb.Table(\n",
    "        columns=[\"Metric\", \"Paper (Pix2Pix)\", \"Our Results\"],\n",
    "        data=[\n",
    "            [\"Position X Error (pixels)\", \"6.28 ± 7.98\", f\"{results['test/position_x_mean']:.2f} ± {results['test/position_x_std']:.2f}\"],\n",
    "            [\"Position Y Error (pixels)\", \"11.7 ± 12.8\", f\"{results['test/position_y_mean']:.2f} ± {results['test/position_y_std']:.2f}\"],\n",
    "            [\"Failure Rate (%)\", \"7%\", f\"{failure_rate:.2f}%\"]\n",
    "        ]\n",
    "    )\n",
    "    wandb.log({\"comparison_with_paper\": comparison_table})\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(f\"Total: {total_predictions}, Failed: {failed_predictions} ({failure_rate:.2f}%)\")\n",
    "    \n",
    "    if len(all_errors_x) > 0:\n",
    "        print(f\"\\nPosition X Error: {results['test/position_x_mean']:.2f} ± {results['test/position_x_std']:.2f} pixels\")\n",
    "        print(f\"Position Y Error: {results['test/position_y_mean']:.2f} ± {results['test/position_y_std']:.2f} pixels\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPARISON WITH PAPER RESULTS\")\n",
    "    print(\"Paper Pix2Pix Results:\")\n",
    "    print(\"  Position X: 6.28 ± 7.98 pixels\")\n",
    "    print(\"  Position Y: 11.7 ± 12.8 pixels\")\n",
    "    print(\"  Rotation: 17.2 ± 20.8 degrees\")\n",
    "    print(\"  Roundness: 0.56 ± 0.14 pixels\")\n",
    "    print(\"  Failure Rate: 7%\")\n",
    "    print(\"  Number of balls: 93% single ball, 7% no/multiple balls\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jet/home/rnagaraj/bounce_ball_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.abspath(\"bounce_ball_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main(use_wandb=True, wandb_project=\"physicsgen-pix2pix\", wandb_entity=None):\n",
    "    DATA_ROOT = 'bounce_ball_data/bounce_ball'\n",
    "    \n",
    "    CONFIG = {\n",
    "        'batch_size': 18,\n",
    "        'lr_discriminator': 1e-4, #try changing to 5e-5\n",
    "        'lr_generator': 2e-4,\n",
    "        'num_epochs': 50,\n",
    "        'lambda_l1': 100,\n",
    "        'lambda_gp': 10,\n",
    "        'image_size': 256,\n",
    "        'num_workers': 2,\n",
    "        'split_direction': 'horizontal',\n",
    "    }\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.init(\n",
    "            project=wandb_project,\n",
    "            entity=wandb_entity,\n",
    "            config=CONFIG,\n",
    "            name=f\"pix2pix-instancenorm-gp\",\n",
    "            tags=['pix2pix', 'instancenorm', 'gradient-penalty', 'physicsgen']\n",
    "        )\n",
    "        config = wandb.config\n",
    "    else:\n",
    "        config = CONFIG\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        DATA_ROOT,\n",
    "        batch_size=config['batch_size'],\n",
    "        image_size=config['image_size'],\n",
    "        num_workers=config['num_workers'],\n",
    "        split_direction=config['split_direction']\n",
    "    )\n",
    "    \n",
    "    generator = Generator().to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "    print(f\"\\nGenerator params: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "    print(f\"Discriminator params: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.watch(generator, log='all', log_freq=100)\n",
    "        wandb.watch(discriminator, log='all', log_freq=100)\n",
    "    \n",
    "    train_pix2pix(generator, discriminator, train_loader, val_loader, config, device)\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.finish()\n",
    "    \n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HW2P2_final_submission.zip  kaggle_data.json\n",
      "HW3P2_final_submission.zip  model_arch.txt\n",
      "HW3P2_v10.ipynb\t\t    model_metadata_2025-10-12_18-23.json\n",
      "IDL-hw4\t\t\t    model_metadata_2025-10-12_18-49.json\n",
      "README.txt\t\t    model_metadata_2025-10-31_15-12.json\n",
      "acknowledgement.txt\t    model_metadata_2025-11-09_19-09.json\n",
      "bounce_ball.zip\t\t    model_metadata_2025-11-09_19-21.json\n",
      "bounce_ball_data\t    my_hw4_env\n",
      "checkpoint\t\t    ondemand\n",
      "checkpoint_p3_new\t    submission.csv\n",
      "checkpoint_submission.json  verification_early_submission.csv\n",
      "checkpoints\t\t    wandb\n",
      "config.yaml\t\t    wandb_top_runs.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/jet/home/rnagaraj/wandb/run-20251202_140202-8p5gkk4o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix/runs/8p5gkk4o' target=\"_blank\">pix2pix-instancenorm-gp</a></strong> to <a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix' target=\"_blank\">https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix/runs/8p5gkk4o' target=\"_blank\">https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix/runs/8p5gkk4o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Split direction: horizontal\n",
      "\n",
      "Train set:\n",
      "44835 combined images from bounce_ball_data/bounce_ball/train_double\n",
      "  Image size: 1024x512\n",
      "  Will split into: 512x512 (left) and 512x512 (right)\n",
      "\n",
      "Validation set:\n",
      "58 combined images from bounce_ball_data/bounce_ball/val_double\n",
      "  Image size: 1024x512\n",
      "  Will split into: 512x512 (left) and 512x512 (right)\n",
      "\n",
      "Test set:\n",
      "1600 combined images from bounce_ball_data/bounce_ball/test_double\n",
      "  Image size: 1024x512\n",
      "  Will split into: 512x512 (left) and 512x512 (right)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m USE_WANDB = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      4\u001b[39m WANDB_PROJECT = \u001b[33m\"\u001b[39m\u001b[33mphysicsgen-pix2pix\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m generator, discriminator = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSE_WANDB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwandb_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWANDB_PROJECT\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(use_wandb, wandb_project, wandb_entity)\u001b[39m\n\u001b[32m     31\u001b[39m train_loader, val_loader, test_loader = create_data_loaders(\n\u001b[32m     32\u001b[39m     DATA_ROOT,\n\u001b[32m     33\u001b[39m     batch_size=config[\u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     split_direction=config[\u001b[33m'\u001b[39m\u001b[33msplit_direction\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m generator = Generator().to(device)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m discriminator = \u001b[43mDiscriminator\u001b[49m().to(device)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGenerator params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mgenerator.parameters())\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDiscriminator params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mdiscriminator.parameters())\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'Discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    DATA_ROOT = 'bounce_ball_data/bounce_ball'\n",
    "    USE_WANDB = True\n",
    "    WANDB_PROJECT = \"physicsgen-pix2pix\"\n",
    "    \n",
    "    generator, discriminator = main(\n",
    "        use_wandb=USE_WANDB,\n",
    "        wandb_project=WANDB_PROJECT\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8558578,
     "sourceId": 13480612,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "My HW4 Kernel",
   "language": "python",
   "name": "my_hw4_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
