{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating environment at: /jet/home/rnagaraj/my_hw4_env ...\n",
      "Installing libraries...\n",
      "Requirement already satisfied: torch in ./my_hw4_env/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in ./my_hw4_env/lib/python3.11/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy in ./my_hw4_env/lib/python3.11/site-packages (2.2.6)\n",
      "Requirement already satisfied: Pillow in ./my_hw4_env/lib/python3.11/site-packages (12.0.0)\n",
      "Requirement already satisfied: opencv-python in ./my_hw4_env/lib/python3.11/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in ./my_hw4_env/lib/python3.11/site-packages (3.10.7)\n",
      "Requirement already satisfied: tqdm in ./my_hw4_env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: wandb in ./my_hw4_env/lib/python3.11/site-packages (0.23.0)\n",
      "Requirement already satisfied: ipykernel in ./my_hw4_env/lib/python3.11/site-packages (7.1.0)\n",
      "Requirement already satisfied: filelock in ./my_hw4_env/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./my_hw4_env/lib/python3.11/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./my_hw4_env/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./my_hw4_env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./my_hw4_env/lib/python3.11/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./my_hw4_env/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./my_hw4_env/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./my_hw4_env/lib/python3.11/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./my_hw4_env/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: click>=8.0.1 in ./my_hw4_env/lib/python3.11/site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./my_hw4_env/lib/python3.11/site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in ./my_hw4_env/lib/python3.11/site-packages (from wandb) (4.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in ./my_hw4_env/lib/python3.11/site-packages (from wandb) (6.33.1)\n",
      "Requirement already satisfied: pydantic<3 in ./my_hw4_env/lib/python3.11/site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: pyyaml in ./my_hw4_env/lib/python3.11/site-packages (from wandb) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./my_hw4_env/lib/python3.11/site-packages (from wandb) (2.32.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./my_hw4_env/lib/python3.11/site-packages (from wandb) (2.46.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (9.7.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: psutil>=5.7 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (7.1.3)\n",
      "Requirement already satisfied: pyzmq>=25 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./my_hw4_env/lib/python3.11/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./my_hw4_env/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./my_hw4_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./my_hw4_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./my_hw4_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./my_hw4_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./my_hw4_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./my_hw4_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./my_hw4_env/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./my_hw4_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./my_hw4_env/lib/python3.11/site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./my_hw4_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in ./my_hw4_env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./my_hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./my_hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./my_hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./my_hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./my_hw4_env/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./my_hw4_env/lib/python3.11/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./my_hw4_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./my_hw4_env/lib/python3.11/site-packages (from jedi>=0.18.1->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./my_hw4_env/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./my_hw4_env/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./my_hw4_env/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./my_hw4_env/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./my_hw4_env/lib/python3.11/site-packages (from stack_data>=0.6.0->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/jet/home/rnagaraj/my_hw4_env/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Registering kernel...\n",
      "Installed kernelspec my_hw4_kernel in /jet/home/rnagaraj/.local/share/jupyter/kernels/my_hw4_kernel\n",
      "\n",
      "SUCCESS! Now refresh the page and change your kernel.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "env_path = os.path.expanduser(\"~/my_hw4_env\")\n",
    "print(f\"Creating environment at: {env_path} ...\")\n",
    "\n",
    "!python -m venv {env_path}\n",
    "print(\"Installing libraries...\")\n",
    "!{env_path}/bin/pip install torch torchvision numpy Pillow opencv-python matplotlib tqdm wandb ipykernel\n",
    "print(\"Registering kernel...\")\n",
    "!{env_path}/bin/python -m ipykernel install --user --name=my_hw4_kernel --display-name \"My HW4 Kernel\"\n",
    "\n",
    "print(\"\\nSUCCESS! Now refresh the page and change your kernel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (2.5.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: Pillow in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (11.0.0)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: matplotlib in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: tqdm in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: wandb in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (0.19.9)\n",
      "Requirement already satisfied: filelock in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch)\n",
      "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (2.10.5)\n",
      "Requirement already satisfied: pyyaml in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (2.19.2)\n",
      "Requirement already satisfied: setproctitle in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from wandb) (78.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.4.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "Using cached torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "Using cached nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "Using cached nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Using cached nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, triton, sympy, opencv-python, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "\u001b[?25l\u001b[31mERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: '/ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env/lib/python3.11/site-packages/nvidia/cusparselt'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/20\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision numpy Pillow opencv-python matplotlib tqdm wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pix2Pix Implementation for PhysicsGen Motion Prediction\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    print(\"Installing wandb...\")\n",
    "    !pip install wandb -q\n",
    "    import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:20:54.963027Z",
     "iopub.status.busy": "2025-11-24T00:20:54.962672Z",
     "iopub.status.idle": "2025-11-24T00:21:01.837858Z",
     "shell.execute_reply": "2025-11-24T00:21:01.837105Z",
     "shell.execute_reply.started": "2025-11-24T00:20:54.963003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrishin\u001b[0m (\u001b[33mrishin-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['WANDB_API_KEY'] = 'c0568591bf53551942de5b598dcf8626dae19df1'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HW2P2_final_submission.zip  kaggle_data.json\n",
      "HW3P2_final_submission.zip  model_arch.txt\n",
      "HW3P2_v10.ipynb\t\t    model_metadata_2025-10-12_18-23.json\n",
      "IDL-hw4\t\t\t    model_metadata_2025-10-12_18-49.json\n",
      "README.txt\t\t    model_metadata_2025-10-31_15-12.json\n",
      "acknowledgement.txt\t    model_metadata_2025-11-09_19-09.json\n",
      "bounce_ball.zip\t\t    model_metadata_2025-11-09_19-21.json\n",
      "bounce_ball_data\t    my_hw4_env\n",
      "checkpoint\t\t    ondemand\n",
      "checkpoint_p3_new\t    submission.csv\n",
      "checkpoint_submission.json  verification_early_submission.csv\n",
      "checkpoints\t\t    wandb\n",
      "config.yaml\t\t    wandb_top_runs.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:22:43.610985Z",
     "iopub.status.busy": "2025-11-24T00:22:43.610245Z",
     "iopub.status.idle": "2025-11-24T00:22:43.619345Z",
     "shell.execute_reply": "2025-11-24T00:22:43.618535Z",
     "shell.execute_reply.started": "2025-11-24T00:22:43.610956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CombinedImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None, split_direction='horizontal'):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.split_direction = split_direction\n",
    "        self.image_files = sorted([\n",
    "            f for f in os.listdir(self.data_dir) \n",
    "            if f.endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ])\n",
    "        \n",
    "        print(f\"{len(self.image_files)} combined images from {data_dir}\")\n",
    "        \n",
    "        if self.image_files:\n",
    "            first_img = Image.open(self.data_dir / self.image_files[0])\n",
    "            w, h = first_img.size\n",
    "            print(f\"  Image size: {w}x{h}\")\n",
    "            \n",
    "            if split_direction == 'horizontal':\n",
    "                if w > h * 1.5:\n",
    "                    print(f\"  Will split into: {w//2}x{h} (left) and {w//2}x{h} (right)\")\n",
    "                else:\n",
    "                    print(f\"  Image might not be horizontally combined\")\n",
    "            else:\n",
    "                if h > w * 1.5:\n",
    "                    print(f\"  Will split into: {w}x{h//2} (top) and {w}x{h//2} (bottom)\")\n",
    "                else:\n",
    "                    print(f\"  Image might not be vertically combined\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data_dir / self.image_files[idx]\n",
    "        combined_img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        w, h = combined_img.size\n",
    "        \n",
    "        if self.split_direction == 'horizontal':\n",
    "            mid = w // 2\n",
    "            input_img = combined_img.crop((0, 0, mid, h))\n",
    "            target_img = combined_img.crop((mid, 0, w, h))\n",
    "        else:\n",
    "            mid = h // 2\n",
    "            input_img = combined_img.crop((0, 0, w, mid))\n",
    "            target_img = combined_img.crop((0, mid, w, h))\n",
    "        \n",
    "        if self.transform:\n",
    "            input_img = self.transform(input_img)\n",
    "            target_img = self.transform(target_img)\n",
    "        \n",
    "        return input_img, target_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:22:50.797601Z",
     "iopub.status.busy": "2025-11-24T00:22:50.797324Z",
     "iopub.status.idle": "2025-11-24T00:22:50.804674Z",
     "shell.execute_reply": "2025-11-24T00:22:50.803959Z",
     "shell.execute_reply.started": "2025-11-24T00:22:50.797581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_data_loaders(data_root, batch_size=18, image_size=256, num_workers=2, \n",
    "                       split_direction='horizontal'):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    print(f\"Split direction: {split_direction}\")\n",
    "    \n",
    "    \n",
    "    train_path = Path(data_root) / 'train_double'\n",
    "    print(\"\\nTrain set:\")\n",
    "    train_dataset = CombinedImageDataset(\n",
    "        str(train_path), \n",
    "        transform=transform,\n",
    "        split_direction=split_direction\n",
    "    )\n",
    "    \n",
    "    val_path = Path(data_root) / 'val_double'\n",
    "    test_path = Path(data_root) / 'test_double'\n",
    "    \n",
    "    if val_path.exists():\n",
    "        print(\"\\nValidation set:\")\n",
    "        val_dataset = CombinedImageDataset(\n",
    "            str(val_path), \n",
    "            transform=transform,\n",
    "            split_direction=split_direction\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\nValidation set: Creating 10% split from training\")\n",
    "        train_size = int(0.9 * len(train_dataset))\n",
    "        val_size = len(train_dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "            train_dataset, [train_size, val_size]\n",
    "        )\n",
    "    \n",
    "    if test_path.exists():\n",
    "        print(\"\\nTest set:\")\n",
    "        test_dataset = CombinedImageDataset(\n",
    "            str(test_path), \n",
    "            transform=transform,\n",
    "            split_direction=split_direction\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\nTest set: Using val set\")\n",
    "        test_dataset = val_dataset\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                             shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, \n",
    "                           shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                            shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:22:58.315995Z",
     "iopub.status.busy": "2025-11-24T00:22:58.315727Z",
     "iopub.status.idle": "2025-11-24T00:22:58.322669Z",
     "shell.execute_reply": "2025-11-24T00:22:58.321837Z",
     "shell.execute_reply.started": "2025-11-24T00:22:58.315976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNetDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True, dropout=0.0):\n",
    "        super(UNetDown, self).__init__()\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels, affine=True))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
    "        super(UNetUp, self).__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:23:01.602238Z",
     "iopub.status.busy": "2025-11-24T00:23:01.601486Z",
     "iopub.status.idle": "2025-11-24T00:23:01.610161Z",
     "shell.execute_reply": "2025-11-24T00:23:01.609368Z",
     "shell.execute_reply.started": "2025-11-24T00:23:01.602207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False) \n",
    "        self.down2 = UNetDown(64, 128)                          \n",
    "        self.down3 = UNetDown(128, 256)                       \n",
    "        self.down4 = UNetDown(256, 512)          \n",
    "        self.down5 = UNetDown(512, 512)\n",
    "        self.down6 = UNetDown(512, 512)\n",
    "        self.down7 = UNetDown(512, 512)\n",
    "        self.down8 = UNetDown(512, 512, normalize=False) \n",
    "\n",
    "        \n",
    "        self.up1 = UNetUp(512, 512, dropout=0.5)\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.5)\n",
    "        self.up3 = UNetUp(1024, 512, dropout=0.5) \n",
    "        self.up4 = UNetUp(1024, 512)\n",
    "        self.up5 = UNetUp(1024, 256)\n",
    "        self.up6 = UNetUp(512, 128) \n",
    "        self.up7 = UNetUp(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, out_channels, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)\n",
    "\n",
    "        \n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "\n",
    "        return self.final(u7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:01.305132Z",
     "iopub.status.busy": "2025-11-24T00:25:01.304413Z",
     "iopub.status.idle": "2025-11-24T00:25:01.311058Z",
     "shell.execute_reply": "2025-11-24T00:25:01.310343Z",
     "shell.execute_reply.started": "2025-11-24T00:25:01.305105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=6):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters, affine=True))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(discriminator, real_A, real_B, fake_B, device, lambda_gp=10):\n",
    "    \n",
    "    batch_size = real_B.size(0)\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    \n",
    "    interpolates = (alpha * real_B + (1 - alpha) * fake_B).requires_grad_(True)\n",
    "    d_interpolates = discriminator(real_A, interpolates)\n",
    "    fake = torch.ones(d_interpolates.size(), device=device, requires_grad=False)\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * lambda_gp\n",
    "    \n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(generator, discriminator, train_loader, optimizer_G, optimizer_D, \n",
    "                criterion_GAN, criterion_L1, lambda_L1, lambda_gp, device, epoch):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    epoch_g_loss = 0\n",
    "    epoch_d_loss = 0\n",
    "    epoch_gan_loss = 0\n",
    "    epoch_l1_loss = 0\n",
    "    epoch_gp_loss = 0 \n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1} - Training')\n",
    "    for batch_idx, (real_A, real_B) in enumerate(pbar):\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "        \n",
    "        batch_size = real_A.size(0)\n",
    "        valid = torch.ones((batch_size, 1, 16, 16), device=device, requires_grad=False)\n",
    "        fake = torch.zeros((batch_size, 1, 16, 16), device=device, requires_grad=False)\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        fake_B = generator(real_A)\n",
    "        pred_fake = discriminator(real_A, fake_B)\n",
    "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "        loss_L1 = criterion_L1(fake_B, real_B)\n",
    "        loss_G = loss_GAN + lambda_L1 * loss_L1\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        pred_real = discriminator(real_A, real_B)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "        \n",
    "        pred_fake = discriminator(real_A, fake_B.detach())\n",
    "        loss_fake = criterion_GAN(pred_fake, fake)\n",
    "        \n",
    "        gp = compute_gradient_penalty(discriminator, real_A, real_B, \n",
    "                                     fake_B.detach(), device, lambda_gp)\n",
    "        \n",
    "        loss_D = 0.5 * (loss_real + loss_fake) + gp\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        epoch_g_loss += loss_G.item()\n",
    "        epoch_d_loss += loss_D.item()\n",
    "        epoch_gan_loss += loss_GAN.item()\n",
    "        epoch_l1_loss += loss_L1.item()\n",
    "        epoch_gp_loss += gp.item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            wandb.log({\n",
    "                'batch/g_loss': loss_G.item(),\n",
    "                'batch/d_loss': loss_D.item(),\n",
    "                'batch/gan_loss': loss_GAN.item(),\n",
    "                'batch/l1_loss': loss_L1.item(),\n",
    "                'batch/gp_loss': gp.item(),\n",
    "                'batch/step': epoch * len(train_loader) + batch_idx\n",
    "            })\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'G': f'{loss_G.item():.4f}',\n",
    "            'D': f'{loss_D.item():.4f}',\n",
    "            'L1': f'{loss_L1.item():.4f}',\n",
    "            'GP': f'{gp.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    return (epoch_g_loss/num_batches, epoch_d_loss/num_batches,\n",
    "            epoch_gan_loss/num_batches, epoch_l1_loss/num_batches,\n",
    "            epoch_gp_loss/num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "def calculate_roundness_loss(prediction):\n",
    "    \"\"\"\n",
    "    Calculates L_roundness: Penalty for geometric distortion.\n",
    "    \n",
    "    Note: Since the exact implementation depends on the specific paper's\n",
    "    definition (e.g., Hough transform differentiability or radial symmetry), \n",
    "    this uses a variance-based approach suitable for 'ball' shapes.\n",
    "    \n",
    "    It calculates the center of mass and penalizes variance in the \n",
    "    distance of activated pixels from that center.\n",
    "    \"\"\"\n",
    "    batch_size, _, h, w = prediction.size()\n",
    "    y_grid, x_grid = torch.meshgrid(torch.arange(h), torch.arange(w), indexing='ij')\n",
    "    y_grid, x_grid = y_grid.to(prediction.device).float(), x_grid.to(prediction.device).float()\n",
    "    pred_sum = torch.sum(prediction, dim=[2, 3], keepdim=True) + 1e-8\n",
    "    pred_norm = prediction / pred_sum\n",
    "    com_x = torch.sum(pred_norm * x_grid, dim=[2, 3], keepdim=True)\n",
    "    com_y = torch.sum(pred_norm * y_grid, dim=[2, 3], keepdim=True)\n",
    "    dist_sq = (x_grid - com_x)**2 + (y_grid - com_y)**2\n",
    "    weighted_dist_variance = torch.sum(pred_norm * dist_sq, dim=[2, 3])\n",
    "    \n",
    "    return torch.mean(weighted_dist_variance)\n",
    "\n",
    "def train_epoch_tpl(generator, discriminator, train_loader, optimizer_G, optimizer_D, \n",
    "                    criterion_GAN, lambda1, lambda2, lambda3, lambda_gp, device, epoch):\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    metrics = {\n",
    "        'g_loss': 0, 'd_loss': 0, 'gan_loss': 0, \n",
    "        'mse_loss': 0, 'round_loss': 0, 'gp_loss': 0\n",
    "    }\n",
    "    criterion_MSE = nn.MSELoss() \n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1} - TPL Training')\n",
    "    \n",
    "    for batch_idx, (real_A, real_B) in enumerate(pbar):\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "        \n",
    "        batch_size = real_A.size(0)\n",
    "        optimizer_D.zero_grad()\n",
    "        fake_B = generator(real_A)\n",
    "        valid = torch.ones((batch_size, 1, 16, 16), device=device, requires_grad=False)\n",
    "        fake = torch.zeros((batch_size, 1, 16, 16), device=device, requires_grad=False)\n",
    "        \n",
    "        pred_real = discriminator(real_A, real_B)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "        pred_fake = discriminator(real_A, fake_B.detach())\n",
    "        loss_fake = criterion_GAN(pred_fake, fake)\n",
    "        gp = compute_gradient_penalty(discriminator, real_A, real_B, \n",
    "                                      fake_B.detach(), device, lambda_gp)\n",
    "        \n",
    "        loss_D = 0.5 * (loss_real + loss_fake) + gp\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        optimizer_G.zero_grad()\n",
    "        pred_fake_G = discriminator(real_A, fake_B) \n",
    "        loss_BCE_valid = criterion_GAN(pred_fake_G, valid)\n",
    "        loss_MSE = criterion_MSE(fake_B, real_B)\n",
    "        loss_Roundness = calculate_roundness_loss(fake_B)\n",
    "        loss_G = (lambda1 * loss_MSE) + \\\n",
    "                 (lambda2 * loss_Roundness) + \\\n",
    "                 (lambda3 * loss_BCE_valid)\n",
    "                 \n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        metrics['g_loss'] += loss_G.item()\n",
    "        metrics['d_loss'] += loss_D.item()\n",
    "        metrics['gan_loss'] += loss_BCE_valid.item()\n",
    "        metrics['mse_loss'] += loss_MSE.item()\n",
    "        metrics['round_loss'] += loss_Roundness.item()\n",
    "        metrics['gp_loss'] += gp.item()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            wandb.log({\n",
    "                'batch/g_loss': loss_G.item(),\n",
    "                'batch/d_loss': loss_D.item(),\n",
    "                'batch/gan_bce_loss': loss_BCE_valid.item(),\n",
    "                'batch/mse_loss': loss_MSE.item(),\n",
    "                'batch/round_loss': loss_Roundness.item(),\n",
    "                'batch/step': epoch * len(train_loader) + batch_idx\n",
    "            })\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'G': f'{loss_G.item():.4f}',\n",
    "            'MSE': f'{loss_MSE.item():.4f}',\n",
    "            'Round': f'{loss_Roundness.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    num_batches = len(train_loader)\n",
    "    return {k: v / num_batches for k, v in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:18.291728Z",
     "iopub.status.busy": "2025-11-24T00:25:18.291034Z",
     "iopub.status.idle": "2025-11-24T00:25:18.297939Z",
     "shell.execute_reply": "2025-11-24T00:25:18.297250Z",
     "shell.execute_reply.started": "2025-11-24T00:25:18.291703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate(generator, discriminator, val_loader, criterion_GAN, \n",
    "             criterion_L1, lambda_L1, device, epoch):\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    val_g_loss = 0\n",
    "    val_d_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for real_A, real_B in tqdm(val_loader, desc=f'Epoch {epoch+1} - Validation'):\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "            \n",
    "            batch_size = real_A.size(0)\n",
    "            valid = torch.ones((batch_size, 1, 16, 16), device=device)\n",
    "            fake = torch.zeros((batch_size, 1, 16, 16), device=device)\n",
    "            \n",
    "            fake_B = generator(real_A)\n",
    "            pred_fake = discriminator(real_A, fake_B)\n",
    "            loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "            loss_L1 = criterion_L1(fake_B, real_B)\n",
    "            loss_G = loss_GAN + lambda_L1 * loss_L1\n",
    "            \n",
    "            pred_real = discriminator(real_A, real_B)\n",
    "            loss_real = criterion_GAN(pred_real, valid)\n",
    "            pred_fake = discriminator(real_A, fake_B)\n",
    "            loss_fake = criterion_GAN(pred_fake, fake)\n",
    "            loss_D = 0.5 * (loss_real + loss_fake)\n",
    "            \n",
    "            val_g_loss += loss_G.item()\n",
    "            val_d_loss += loss_D.item()\n",
    "    \n",
    "    num_batches = len(val_loader)\n",
    "    return val_g_loss/num_batches, val_d_loss/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_pix2pix(generator, discriminator, train_loader, val_loader, \n",
    "                  config, device, save_dir='checkpoints'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    optimizer_G = optim.Adam(generator.parameters(), \n",
    "                            lr=config['lr_generator'], \n",
    "                            betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), \n",
    "                            lr=config['lr_discriminator'], \n",
    "                            betas=(0.5, 0.999))\n",
    "    \n",
    "    criterion_GAN = nn.MSELoss()\n",
    "    criterion_L1 = nn.L1Loss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    print(\"Starting Pix2Pix Training with Gradient Penalty\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Lambda L1: {config['lambda_l1']}\")\n",
    "    print(f\"Lambda GP: {config['lambda_gp']}\") \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        train_g, train_d, train_gan, train_l1, train_gp = train_epoch(\n",
    "            generator, discriminator, train_loader,\n",
    "            optimizer_G, optimizer_D,\n",
    "            criterion_GAN, criterion_L1, \n",
    "            config['lambda_l1'], config['lambda_gp'], \n",
    "            device, epoch\n",
    "        )\n",
    "        val_g, val_d = validate(\n",
    "            generator, discriminator, val_loader,\n",
    "            criterion_GAN, criterion_L1, config['lambda_l1'],\n",
    "            device, epoch\n",
    "        )\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'train/g_loss': train_g,\n",
    "            'train/d_loss': train_d,\n",
    "            'train/gan_loss': train_gan,\n",
    "            'train/l1_loss': train_l1,\n",
    "            'train/gp_loss': train_gp,  \n",
    "            'val/g_loss': val_g,\n",
    "            'val/d_loss': val_d,\n",
    "            'epoch_time': epoch_time\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nEpoch [{epoch+1}/{config['num_epochs']}] | Time: {epoch_time:.1f}s\")\n",
    "        print(f\"  Train - G: {train_g:.4f}, D: {train_d:.4f}, GP: {train_gp:.4f}\")\n",
    "        print(f\"  Val   - G: {val_g:.4f}, D: {val_d:.4f}\")\n",
    "        \n",
    "        if val_g < best_val_loss:\n",
    "            best_val_loss = val_g\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'val_loss': val_g,\n",
    "            }\n",
    "            torch.save(checkpoint, os.path.join(save_dir, 'best_pix2pix.pth'))\n",
    "            wandb.save(os.path.join(save_dir, 'best_pix2pix.pth'))\n",
    "            print(f\"  ✓ Saved best model\")\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            visualize_results(generator, val_loader, device, epoch)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    wandb.run.summary['best_val_loss'] = best_val_loss\n",
    "    wandb.run.summary['total_training_time'] = total_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Training completed in {total_time/3600:.2f} hours\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pix2pix(generator, discriminator, train_loader, val_loader, config, device):\n",
    "    optimizer_G = torch.optim.Adam(\n",
    "        generator.parameters(), \n",
    "        lr=config['lr_generator'], \n",
    "        betas=(0.5, 0.999)\n",
    "    )\n",
    "    optimizer_D = torch.optim.Adam(\n",
    "        discriminator.parameters(), \n",
    "        lr=config['lr_discriminator'], \n",
    "        betas=(0.5, 0.999)\n",
    "    )\n",
    "    criterion_GAN = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        epoch_start = time.time()\n",
    "        metrics = train_epoch_tpl(\n",
    "            generator, discriminator, train_loader, \n",
    "            optimizer_G, optimizer_D,\n",
    "            criterion_GAN, \n",
    "            config['lambda1'], config['lambda2'], config['lambda3'], \n",
    "            config['lambda_gp'], \n",
    "            device, epoch\n",
    "        )\n",
    "        \n",
    "        epoch_duration = time.time() - epoch_start\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{config['num_epochs']} \"\n",
    "              f\"[{epoch_duration:.0f}s] \"\n",
    "              f\"G_Loss: {metrics['g_loss']:.4f} \"\n",
    "              f\"MSE: {metrics['mse_loss']:.4f} \"\n",
    "              f\"Round: {metrics['round_loss']:.4f}\")\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save(generator.state_dict(), f\"generator_epoch_{epoch+1}.pth\")\n",
    "            torch.save(discriminator.state_dict(), f\"discriminator_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:36.568622Z",
     "iopub.status.busy": "2025-11-24T00:25:36.568132Z",
     "iopub.status.idle": "2025-11-24T00:25:36.575482Z",
     "shell.execute_reply": "2025-11-24T00:25:36.574703Z",
     "shell.execute_reply.started": "2025-11-24T00:25:36.568601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_results(generator, val_loader, device, epoch):\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        real_A, real_B = next(iter(val_loader))\n",
    "        real_A = real_A.to(device)\n",
    "        fake_B = generator(real_A)\n",
    "        \n",
    "        def denorm(x):\n",
    "            return (x + 1) / 2\n",
    "        \n",
    "        num_vis = min(4, len(real_A))\n",
    "        fig, axes = plt.subplots(3, num_vis, figsize=(4*num_vis, 12))\n",
    "        \n",
    "        for i in range(num_vis):\n",
    "            input_img = denorm(real_A[i]).cpu().permute(1, 2, 0).numpy()\n",
    "            axes[0, i].imshow(input_img)\n",
    "            axes[0, i].set_title(f'Input {i+1}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            gen_img = denorm(fake_B[i]).cpu().permute(1, 2, 0).numpy()\n",
    "            axes[1, i].imshow(gen_img)\n",
    "            axes[1, i].set_title(f'Generated {i+1}')\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            target_img = denorm(real_B[i]).cpu().permute(1, 2, 0).numpy()\n",
    "            axes[2, i].imshow(target_img)\n",
    "            axes[2, i].set_title(f'Ground Truth {i+1}')\n",
    "            axes[2, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        wandb.log({f\"generations/epoch_{epoch+1}\": wandb.Image(fig), \"epoch\": epoch + 1})\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:46.778697Z",
     "iopub.status.busy": "2025-11-24T00:25:46.778004Z",
     "iopub.status.idle": "2025-11-24T00:25:46.783944Z",
     "shell.execute_reply": "2025-11-24T00:25:46.783217Z",
     "shell.execute_reply.started": "2025-11-24T00:25:46.778671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BallDetector:\n",
    "    \n",
    "    def __init__(self, ball_radius=15, min_radius=10, max_radius=25):\n",
    "        self.ball_radius = ball_radius\n",
    "        self.min_radius = min_radius\n",
    "        self.max_radius = max_radius\n",
    "    \n",
    "    def detect_ball(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        \n",
    "        blurred = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "        circles = cv2.HoughCircles(\n",
    "            blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50,\n",
    "            param1=50, param2=30,\n",
    "            minRadius=self.min_radius, maxRadius=self.max_radius\n",
    "        )\n",
    "        \n",
    "        if circles is None or len(circles[0]) == 0:\n",
    "            return None\n",
    "        \n",
    "        circle = circles[0][0]\n",
    "        return {'position': (circle[0], circle[1]), 'radius': circle[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T00:25:50.735201Z",
     "iopub.status.busy": "2025-11-24T00:25:50.734599Z",
     "iopub.status.idle": "2025-11-24T00:25:50.970211Z",
     "shell.execute_reply": "2025-11-24T00:25:50.969412Z",
     "shell.execute_reply.started": "2025-11-24T00:25:50.735177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_pix2pix(generator, test_loader, device):\n",
    "    generator.eval()\n",
    "    detector = BallDetector()\n",
    "    \n",
    "    all_errors_x = []\n",
    "    all_errors_y = []\n",
    "    failed_predictions = 0\n",
    "    total_predictions = 0\n",
    "    sample_predictions = []\n",
    "    \n",
    "    print(\"Evaluating Pix2Pix Model\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (real_A, real_B) in enumerate(tqdm(test_loader, desc='Evaluating')):\n",
    "            real_A = real_A.to(device)\n",
    "            fake_B = generator(real_A)\n",
    "            \n",
    "            fake_imgs = ((fake_B + 1) / 2 * 255).cpu().numpy().astype(np.uint8)\n",
    "            real_imgs = ((real_B + 1) / 2 * 255).numpy().astype(np.uint8)\n",
    "            \n",
    "            for i in range(len(fake_imgs)):\n",
    "                total_predictions += 1\n",
    "                \n",
    "                pred = fake_imgs[i].transpose(1, 2, 0)\n",
    "                target = real_imgs[i].transpose(1, 2, 0)\n",
    "                \n",
    "                # Log first 10 samples\n",
    "                if len(sample_predictions) < 10:\n",
    "                    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "                    axes[0].imshow(pred)\n",
    "                    axes[0].set_title('Prediction')\n",
    "                    axes[0].axis('off')\n",
    "                    axes[1].imshow(target)\n",
    "                    axes[1].set_title('Ground Truth')\n",
    "                    axes[1].axis('off')\n",
    "                    plt.tight_layout()\n",
    "                    sample_predictions.append(wandb.Image(fig))\n",
    "                    plt.close()\n",
    "                \n",
    "                pred_ball = detector.detect_ball(pred)\n",
    "                target_ball = detector.detect_ball(target)\n",
    "                \n",
    "                if pred_ball is None or target_ball is None:\n",
    "                    failed_predictions += 1\n",
    "                    continue\n",
    "                \n",
    "                pos_error_x = abs(pred_ball['position'][0] - target_ball['position'][0])\n",
    "                pos_error_y = abs(pred_ball['position'][1] - target_ball['position'][1])\n",
    "                \n",
    "                all_errors_x.append(pos_error_x)\n",
    "                all_errors_y.append(pos_error_y)\n",
    "    \n",
    "    failure_rate = (failed_predictions / total_predictions) * 100\n",
    "    \n",
    "    results = {\n",
    "        'test/position_x_mean': np.mean(all_errors_x) if len(all_errors_x) > 0 else 0,\n",
    "        'test/position_x_std': np.std(all_errors_x) if len(all_errors_x) > 0 else 0,\n",
    "        'test/position_y_mean': np.mean(all_errors_y) if len(all_errors_y) > 0 else 0,\n",
    "        'test/position_y_std': np.std(all_errors_y) if len(all_errors_y) > 0 else 0,\n",
    "        'test/failure_rate': failure_rate,\n",
    "        'test/total_predictions': total_predictions,\n",
    "        'test/failed_predictions': failed_predictions\n",
    "    }\n",
    "    \n",
    "    wandb.log(results)\n",
    "    wandb.log({\"test/sample_predictions\": sample_predictions})\n",
    "    \n",
    "    comparison_table = wandb.Table(\n",
    "        columns=[\"Metric\", \"Paper (Pix2Pix)\", \"Our Results\"],\n",
    "        data=[\n",
    "            [\"Position X Error (pixels)\", \"6.28 ± 7.98\", f\"{results['test/position_x_mean']:.2f} ± {results['test/position_x_std']:.2f}\"],\n",
    "            [\"Position Y Error (pixels)\", \"11.7 ± 12.8\", f\"{results['test/position_y_mean']:.2f} ± {results['test/position_y_std']:.2f}\"],\n",
    "            [\"Failure Rate (%)\", \"7%\", f\"{failure_rate:.2f}%\"]\n",
    "        ]\n",
    "    )\n",
    "    wandb.log({\"comparison_with_paper\": comparison_table})\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(f\"Total: {total_predictions}, Failed: {failed_predictions} ({failure_rate:.2f}%)\")\n",
    "    \n",
    "    if len(all_errors_x) > 0:\n",
    "        print(f\"\\nPosition X Error: {results['test/position_x_mean']:.2f} ± {results['test/position_x_std']:.2f} pixels\")\n",
    "        print(f\"Position Y Error: {results['test/position_y_mean']:.2f} ± {results['test/position_y_std']:.2f} pixels\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPARISON WITH PAPER RESULTS\")\n",
    "    print(\"Paper Pix2Pix Results:\")\n",
    "    print(\"  Position X: 6.28 ± 7.98 pixels\")\n",
    "    print(\"  Position Y: 11.7 ± 12.8 pixels\")\n",
    "    print(\"  Rotation: 17.2 ± 20.8 degrees\")\n",
    "    print(\"  Roundness: 0.56 ± 0.14 pixels\")\n",
    "    print(\"  Failure Rate: 7%\")\n",
    "    print(\"  Number of balls: 93% single ball, 7% no/multiple balls\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jet/home/rnagaraj/bounce_ball_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.abspath(\"bounce_ball_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main(use_wandb=True, wandb_project=\"physicsgen-pix2pix\", wandb_entity=None):\n",
    "    DATA_ROOT = 'bounce_ball_data/bounce_ball'\n",
    "    \n",
    "    CONFIG = {\n",
    "        'batch_size': 18,\n",
    "        'lr_discriminator': 1e-4, #try changing to 5e-5\n",
    "        'lr_generator': 2e-4,\n",
    "        'num_epochs': 50,\n",
    "        'lambda_l1': 100,\n",
    "        'lambda_gp': 10,\n",
    "        'image_size': 256,\n",
    "        'num_workers': 2,\n",
    "        'split_direction': 'horizontal',\n",
    "    }\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.init(\n",
    "            project=wandb_project,\n",
    "            entity=wandb_entity,\n",
    "            config=CONFIG,\n",
    "            name=f\"pix2pix-instancenorm-gp\",\n",
    "            tags=['pix2pix', 'instancenorm', 'gradient-penalty', 'physicsgen']\n",
    "        )\n",
    "        config = wandb.config\n",
    "    else:\n",
    "        config = CONFIG\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        DATA_ROOT,\n",
    "        batch_size=config['batch_size'],\n",
    "        image_size=config['image_size'],\n",
    "        num_workers=config['num_workers'],\n",
    "        split_direction=config['split_direction']\n",
    "    )\n",
    "    \n",
    "    generator = Generator().to(device)\n",
    "    discriminator = Discriminator().to(device)\n",
    "    print(f\"\\nGenerator params: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "    print(f\"Discriminator params: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.watch(generator, log='all', log_freq=100)\n",
    "        wandb.watch(discriminator, log='all', log_freq=100)\n",
    "    \n",
    "    train_pix2pix(generator, discriminator, train_loader, val_loader, config, device)\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.finish()\n",
    "    \n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(use_wandb=True, wandb_project=\"physicsgen-pix2pix\", wandb_entity=None):\n",
    "    DATA_ROOT = 'bounce_ball_data/bounce_ball'\n",
    "    \n",
    "    CONFIG = {\n",
    "        'batch_size': 18,\n",
    "        'lr_discriminator': 1e-4, \n",
    "        'lr_generator': 2e-4,\n",
    "        'num_epochs': 50,\n",
    "        'lambda1': 100.0,  \n",
    "        'lambda2': 10.0, \n",
    "        'lambda3': 1.0, \n",
    "        # ----------------------------------------------\n",
    "        \n",
    "        'lambda_gp': 10,\n",
    "        'image_size': 256,\n",
    "        'num_workers': 2,\n",
    "        'split_direction': 'horizontal',\n",
    "    }\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.init(\n",
    "            project=wandb_project,\n",
    "            entity=wandb_entity,\n",
    "            config=CONFIG,\n",
    "            name=f\"pix2pix-TPL-loss\", \n",
    "            tags=['pix2pix', 'TPL', 'physicsgen', 'roundness-loss']\n",
    "        )\n",
    "        config = wandb.config\n",
    "    else:\n",
    "        config = CONFIG\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        DATA_ROOT,\n",
    "        batch_size=config['batch_size'],\n",
    "        image_size=config['image_size'],\n",
    "        num_workers=config['num_workers'],\n",
    "        split_direction=config['split_direction']\n",
    "    )\n",
    "    generator = Generator().to(device)\n",
    "    discriminator = Discriminator().to(device) \n",
    "    \n",
    "    print(f\"\\nGenerator params: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "    print(f\"Discriminator params: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.watch(generator, log='all', log_freq=100)\n",
    "        wandb.watch(discriminator, log='all', log_freq=100)\n",
    "    train_pix2pix(generator, discriminator, train_loader, val_loader, config, device)\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.finish()\n",
    "    \n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HW2P2_final_submission.zip  kaggle_data.json\n",
      "HW3P2_final_submission.zip  model_arch.txt\n",
      "HW3P2_v10.ipynb\t\t    model_metadata_2025-10-12_18-23.json\n",
      "IDL-hw4\t\t\t    model_metadata_2025-10-12_18-49.json\n",
      "README.txt\t\t    model_metadata_2025-10-31_15-12.json\n",
      "acknowledgement.txt\t    model_metadata_2025-11-09_19-09.json\n",
      "bounce_ball.zip\t\t    model_metadata_2025-11-09_19-21.json\n",
      "bounce_ball_data\t    my_hw4_env\n",
      "checkpoint\t\t    ondemand\n",
      "checkpoint_p3_new\t    submission.csv\n",
      "checkpoint_submission.json  verification_early_submission.csv\n",
      "checkpoints\t\t    wandb\n",
      "config.yaml\t\t    wandb_top_runs.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pix2pix-TPL-loss</strong> at: <a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix/runs/htrw2ryl' target=\"_blank\">https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix/runs/htrw2ryl</a><br> View project at: <a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix' target=\"_blank\">https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251202_141745-htrw2ryl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/jet/home/rnagaraj/wandb/run-20251202_142822-phvbt6j7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix/runs/phvbt6j7' target=\"_blank\">pix2pix-TPL-loss</a></strong> to <a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix' target=\"_blank\">https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix/runs/phvbt6j7' target=\"_blank\">https://wandb.ai/rishin-carnegie-mellon-university/physicsgen-pix2pix/runs/phvbt6j7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Split direction: horizontal\n",
      "\n",
      "Train set:\n",
      "44835 combined images from bounce_ball_data/bounce_ball/train_double\n",
      "  Image size: 1024x512\n",
      "  Will split into: 512x512 (left) and 512x512 (right)\n",
      "\n",
      "Validation set:\n",
      "58 combined images from bounce_ball_data/bounce_ball/val_double\n",
      "  Image size: 1024x512\n",
      "  Will split into: 512x512 (left) and 512x512 (right)\n",
      "\n",
      "Test set:\n",
      "1600 combined images from bounce_ball_data/bounce_ball/test_double\n",
      "  Image size: 1024x512\n",
      "  Will split into: 512x512 (left) and 512x512 (right)\n",
      "\n",
      "Generator params: 54,413,955\n",
      "Discriminator params: 2,769,600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - TPL Training: 100%|█| 2491/2491 [10:26<00:00,  3.98it/s, G=-335201.2188, MSE=0.8365, Round=-33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [627s] G_Loss: -46610478.6044 MSE: 0.8471 Round: -4661056.5279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - TPL Training: 100%|█| 2491/2491 [10:20<00:00,  4.01it/s, G=-194331.6875, MSE=1.0814, Round=-19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [621s] G_Loss: -503425.3795 MSE: 1.0186 Round: -50352.8298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - TPL Training: 100%|█| 2491/2491 [10:18<00:00,  4.03it/s, G=-267367.7500, MSE=1.0739, Round=-26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [618s] G_Loss: -203806.5793 MSE: 1.0651 Round: -20391.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - TPL Training: 100%|█| 2491/2491 [10:18<00:00,  4.03it/s, G=89578.9453, MSE=1.1180, Round=8946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [618s] G_Loss: -545640.2522 MSE: 1.0662 Round: -54574.8026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - TPL Training: 100%|█| 2491/2491 [10:20<00:00,  4.02it/s, G=89233.8203, MSE=1.1252, Round=8912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [620s] G_Loss: 89419.0994 MSE: 1.1170 Round: 8930.6191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - TPL Training: 100%|█| 2491/2491 [10:20<00:00,  4.01it/s, G=89237.0625, MSE=1.1212, Round=8912.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [621s] G_Loss: 89171.2802 MSE: 1.1167 Round: 8905.8416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - TPL Training: 100%|█| 2491/2491 [10:18<00:00,  4.03it/s, G=86716.6094, MSE=1.1244, Round=8660.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [619s] G_Loss: 88161.7127 MSE: 1.1155 Round: 8804.8942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - TPL Training: 100%|█| 2491/2491 [10:17<00:00,  4.03it/s, G=76792.8203, MSE=1.1096, Round=7668.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [618s] G_Loss: 83340.9558 MSE: 1.1101 Round: 8322.8705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - TPL Training: 100%|█| 2491/2491 [10:21<00:00,  4.01it/s, G=105729.0000, MSE=0.8193, Round=1056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [622s] G_Loss: 25791.1975 MSE: 0.9871 Round: 2569.1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - TPL Training: 100%|█| 2491/2491 [10:18<00:00,  4.03it/s, G=104616.7031, MSE=0.8227, Round=104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [618s] G_Loss: 105160.4246 MSE: 0.8282 Round: 10507.6465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - TPL Training: 100%|█| 2491/2491 [10:21<00:00,  4.01it/s, G=100385.9688, MSE=0.8414, Round=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [621s] G_Loss: 103308.4637 MSE: 0.8331 Round: 10322.4011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - TPL Training: 100%|█| 2491/2491 [10:16<00:00,  4.04it/s, G=102053.1484, MSE=0.8317, Round=101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [617s] G_Loss: 44999.0301 MSE: 0.8056 Round: 4491.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - TPL Training: 100%|█| 2491/2491 [10:20<00:00,  4.01it/s, G=93567.1875, MSE=0.8605, Round=9347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [621s] G_Loss: 99118.8416 MSE: 0.8403 Round: 9903.3665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - TPL Training: 100%|█| 2491/2491 [10:19<00:00,  4.02it/s, G=91012.8906, MSE=1.1128, Round=9090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [619s] G_Loss: 67066.9310 MSE: 0.9501 Round: 6697.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - TPL Training: 100%|█| 2491/2491 [10:23<00:00,  3.99it/s, G=96205.2656, MSE=1.4718, Round=9605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [624s] G_Loss: 46951.9952 MSE: 1.1595 Round: 4683.4796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - TPL Training: 100%|█| 2491/2491 [10:19<00:00,  4.02it/s, G=-47176.8281, MSE=1.2722, Round=-47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [619s] G_Loss: 42276.9884 MSE: 1.3880 Round: 4213.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - TPL Training: 100%|█| 2491/2491 [10:18<00:00,  4.03it/s, G=89865.6875, MSE=1.2574, Round=8973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [618s] G_Loss: -59261233753.3544 MSE: 1.3024 Round: -5926123388.4821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - TPL Training: 100%|█| 2491/2491 [10:15<00:00,  4.05it/s, G=56288.9141, MSE=1.4503, Round=5614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [615s] G_Loss: 39968.1198 MSE: 1.3913 Round: 3982.7689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - TPL Training: 100%|█| 2491/2491 [10:19<00:00,  4.02it/s, G=36932.5469, MSE=1.4866, Round=3678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [619s] G_Loss: 51325.4854 MSE: 1.4535 Round: 5117.8794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - TPL Training: 100%|█| 2491/2491 [10:15<00:00,  4.04it/s, G=-1264.5804, MSE=1.4520, Round=-141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [616s] G_Loss: -7746.3276 MSE: 1.4439 Round: -789.2049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - TPL Training: 100%|█| 2491/2491 [10:13<00:00,  4.06it/s, G=46516.1719, MSE=1.1717, Round=4639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [614s] G_Loss: -864222.6966 MSE: 1.3749 Round: -86436.1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - TPL Training: 100%|█| 2491/2491 [10:16<00:00,  4.04it/s, G=60096.3594, MSE=1.0249, Round=5999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [616s] G_Loss: 47948.8926 MSE: 1.0742 Round: 4784.0243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - TPL Training: 100%|█| 2491/2491 [10:19<00:00,  4.02it/s, G=57814.2383, MSE=1.0474, Round=5770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [620s] G_Loss: 59880.0569 MSE: 1.0351 Round: 5977.5336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - TPL Training: 100%|█| 2491/2491 [10:21<00:00,  4.01it/s, G=50537.6133, MSE=1.0922, Round=5042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [621s] G_Loss: 1404.1072 MSE: 1.0807 Round: 129.4803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - TPL Training: 100%|█| 2491/2491 [10:16<00:00,  4.04it/s, G=47977.2734, MSE=1.0859, Round=4786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [616s] G_Loss: 50652.1313 MSE: 1.0848 Round: 5054.2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 - TPL Training: 100%|█| 2491/2491 [10:21<00:00,  4.01it/s, G=45604.8281, MSE=1.0925, Round=4549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [621s] G_Loss: 47961.2698 MSE: 1.0903 Round: 4785.0996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 - TPL Training: 100%|█| 2491/2491 [10:21<00:00,  4.01it/s, G=20983.3086, MSE=1.1223, Round=2086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [621s] G_Loss: 36240.8835 MSE: 1.1086 Round: 3612.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 - TPL Training: 100%|█| 2491/2491 [10:20<00:00,  4.02it/s, G=36382.7930, MSE=1.3086, Round=3625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 [620s] G_Loss: -33392.2342 MSE: 1.2058 Round: -3351.4085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 - TPL Training: 100%|█| 2491/2491 [10:16<00:00,  4.04it/s, G=81031.3281, MSE=1.2727, Round=8090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 [616s] G_Loss: -211062.2888 MSE: 1.2947 Round: -21119.3044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 - TPL Training: 100%|█| 2491/2491 [10:22<00:00,  4.00it/s, G=86100.3984, MSE=1.2763, Round=8597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [622s] G_Loss: 80780.1226 MSE: 1.2829 Round: 8065.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 - TPL Training: 100%|█| 2491/2491 [10:24<00:00,  3.99it/s, G=69383.8750, MSE=1.2613, Round=6925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [624s] G_Loss: 75720.5409 MSE: 1.2772 Round: 7559.1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 - TPL Training: 100%|█| 2491/2491 [10:17<00:00,  4.03it/s, G=55527.1562, MSE=1.2255, Round=5540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 [618s] G_Loss: 49992.9732 MSE: 1.1736 Round: 4987.4358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 - TPL Training: 100%|█| 2491/2491 [10:20<00:00,  4.01it/s, G=-147210.2812, MSE=1.1860, Round=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 [620s] G_Loss: -128388.6202 MSE: 1.2661 Round: -12851.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 - TPL Training: 100%|█| 2491/2491 [10:15<00:00,  4.05it/s, G=-128457.1719, MSE=1.2060, Round=-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 [615s] G_Loss: -217787.6693 MSE: 1.2106 Round: -21790.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 - TPL Training:  93%|▉| 2316/2491 [09:40<00:43,  4.01it/s, G=89946.1484, MSE=1.1306, Round=8983"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://127.0.0.1:8889/'. Verify the server is running and reachable."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    DATA_ROOT = 'bounce_ball_data/bounce_ball'\n",
    "    USE_WANDB = True\n",
    "    WANDB_PROJECT = \"physicsgen-pix2pix\"\n",
    "    \n",
    "    generator, discriminator = main(\n",
    "        use_wandb=USE_WANDB,\n",
    "        wandb_project=WANDB_PROJECT\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8558578,
     "sourceId": 13480612,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "My HW4 Kernel",
   "language": "python",
   "name": "my_hw4_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
